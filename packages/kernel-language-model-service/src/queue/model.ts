import type { LanguageModel, ModelInfo } from '../types.ts';
import { objectResponseFormatter } from './response.ts';
import type { ResponseFormatter } from './response.ts';
import type { Tokenizer } from './tokenizer.ts';
import { whitespaceTokenizer } from './tokenizer.ts';
import {
  makeAbortableAsyncIterable,
  makeEmptyStreamWithAbort,
  mapAsyncIterable,
  normalizeToAsyncIterable,
} from './utils.ts';
import type { StreamWithAbort } from './utils.ts';

/**
 * Queue-based language model with helper methods for configuring responses.
 * Responses are queued and consumed by sample() calls.
 *
 * @template Response - The type of response generated by the model
 */
export type QueueLanguageModel<Response extends object> =
  // QueueLanguageModel does not support any sample options
  LanguageModel</* Options = */ unknown, Response> & {
    /**
     * Pushes a streaming response to the queue for the next sample() call.
     * The text will be tokenized and streamed token by token.
     *
     * @param text - The complete text to stream
     */
    push: (text: string) => void;
  };

/**
 * Make a queue-based language model instance.
 *
 * @template Response - The type of response generated by the model
 * @param options - Configuration options for the model
 * @param options.tokenizer - The tokenizer function to use. Defaults to whitespace splitting.
 * @param options.responseFormatter - The function to use to format each yielded token into a response. Defaults to an object with a response and done property.
 * @param options.responseQueue - For testing only. The queue to use for responses. Defaults to an empty array.
 * @returns A queue-based language model instance.
 */
export const makeQueueModel = <
  Response extends object = { response: string; done: boolean },
>({
  tokenizer = whitespaceTokenizer,
  responseFormatter = objectResponseFormatter as ResponseFormatter<Response>,
  // Available for testing
  responseQueue = [],
}: {
  tokenizer?: Tokenizer;
  responseFormatter?: ResponseFormatter<Response>;
  responseQueue?: StreamWithAbort<Response>[];
} = {}): QueueLanguageModel<Response> => {
  const makeStreamWithAbort = (text: string): StreamWithAbort<Response> =>
    makeAbortableAsyncIterable(
      mapAsyncIterable(
        normalizeToAsyncIterable(tokenizer(text)),
        responseFormatter,
      ),
    );

  return harden({
    getInfo: async (): Promise<ModelInfo<Record<string, never>>> => ({
      model: 'test',
    }),
    load: async (): Promise<void> => {
      // No-op: queue model doesn't require loading
    },
    unload: async (): Promise<void> => {
      // No-op: queue model doesn't require unloading
    },
    sample: async (): Promise<StreamWithAbort<Response>> => {
      return responseQueue.shift() ?? makeEmptyStreamWithAbort();
    },
    push: (text: string): void => {
      const streamWithAbort = makeStreamWithAbort(text);
      responseQueue.push(streamWithAbort);
    },
  });
};
